package org.smallfoot.vw4 ;

/** @file */

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.PrintStream;
import java.util.Vector;
import java.util.TreeMap;
import java.util.TreeSet;
import java.util.regex.Pattern;
import javax.activation.DataSource;
import javax.activation.URLDataSource;
import javax.xml.XMLConstants;
import javax.xml.namespace.QName;
import javax.xml.xpath.XPath;
import javax.xml.xpath.XPathExpression;
import javax.xml.xpath.XPathFactory;
import gnu.getopt.Getopt;
import gnu.getopt.LongOpt;
import org.smallfoot.parser.FCParser;
import org.smallfoot.parser.zone.ZPAliasEntry;
import org.smallfoot.parser.zone.ZoneParser;
import org.smallfoot.vw4.VWImport;
import org.smallfoot.wwn.DevRole;
import org.smallfoot.wwn.WWNDesc;
import org.smallfoot.wwn.WWNDesc.WWNDescSwitch;
import org.smallfoot.wwn.WWNDesc.WWNDescTarget;
import org.smallfoot.wwn.WWNDescription;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;


/* The following is conditionally permitted based on the mutually-exclusive choice at ./configure time.  --with-json= chooses exactly one of the following, causing one of the following comment blocks pairs to be butchered */
/* *@DO_JSON_JAVA_TRUE@/	import org.json.*;				/@DO_JSON_JAVA_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.core.json.*;	/@DO_JSON_JACKSON_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.core.*;		/@DO_JSON_JACKSON_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.databind.*;	/@DO_JSON_JACKSON_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.databind.jsonschema.*;	/@DO_JSON_JACKSON_TRUE@* */

/**
 * VirtualWisdom4ClientTool is a "Swiss Army Knife" of tools used when working with
 * VirtualWisdom4.  The existence of these tools is not a judgement on VirtualWisdom4's
 * proper Engineering; rather, an acceptance that a faster-response solution for the
 * longer-tail of the normal curve is often helpful swapping QA delay for reduced customer
 * friction.
 *
 * As you'd expect, there is no support for this.  If it breaks, you may choose to keep both
 * pieces :)
 *
 * Ad-Hoc content for this utility-stack may appear at http://fcfae.com/
 */
public class VirtualWisdom4ClientTool
{
    private org.w3c.dom.Document xmlDocument;		/**< eventually used to hold an XML document when converting XML<-->JSON<-->XML */

    /**
     * Class Constructor to create with an initial file to load.
     *
     * @param xmlFile File to load at start
     *
     * @see #load(String)
     */
    public VirtualWisdom4ClientTool(String xmlFile)
    {
        this();
        load(xmlFile);
    }

    /**
     * Class Constructor with no initial file.
     */
    public VirtualWisdom4ClientTool()
    {
        FCParser.registerProtocols();
    }

    public VWImport vwimport = null;		/**< singleton list of JSON-writable objects accessed through vwimport() */
    protected VWImport vwimport()
    {
        if (null == vwimport) vwimport = new VWImport();   /**< singleton to access vwimport to allow for later post-process @return vwimport instance, created if needed */
        return vwimport;
    }

    /**
     * Open a file.
     *
     * This is actually a wrapper for the underlying file load
     *
     * @param filename file to load
     * @throw IOException when File() encounters an error instaitating (typically path or permissions)
     */
    protected void _load(String filename)
    throws java.io.IOException
    {
        com.fasterxml.jackson.databind.ObjectMapper mapper = new com.fasterxml.jackson.databind.ObjectMapper();
        /** @todo: evaluate: mapper.configure(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES, false);  */

        vwimport = mapper.readValue(new File(filename), VWImport.class);
    }

    /**
     * Wrapper to just load the file, spitting out exceptions and stacks as they occur.
     *
     * @param filename file to load
     */
    public void load(String filename)
    {
        try
        {
            _load (filename);
        }
        catch (java.io.IOException ioe)
        {
            System.out.println("IO Exception reading from "+filename+": "+ioe.getMessage());
        }
        catch (java.lang.Exception e)
        {
            e.printStackTrace();
        }
    }

    /**
     * Save the current XML Document to a new file.
     *
     * @param filename filename to save into
     */
    protected void _save(String filename)
    throws java.lang.Exception
    {
        throw new java.lang.Exception ("unimplemented");
    }

    /**
     * Wrapper to just save the file, spitting out exceptions and stacks as they occur.
     *
     * @param filename filename to save into
     */
    public void save (String filename)
    {
        try
        {
            _save (filename);
        }
        catch (java.lang.Exception e)
        {
            e.printStackTrace();
        }
    }


    /**
     * Convenience function to generate a pretty-printed JSON text string
     *
     * @param v VWImport object to markup
     * @return a pretty-printed JSON using ObjectWriter.withDefaultPrettyPrinter() or null if an exception occurs
     */
    public String prettyJSON(VWImport v)
    {
        ObjectMapper mapper = new ObjectMapper();
        mapper.setSerializationInclusion(com.fasterxml.jackson.annotation.JsonInclude.Include.NON_NULL);

        try
        {
            ObjectWriter ow = mapper.writer().withDefaultPrettyPrinter();
            return ow.writeValueAsString(v);
        }
        catch (JsonMappingException jme)
        {
            System.err.println("INTERNAL: A JsonMappingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
            System.out.println(jme.getMessage());
            return null;
        }
        catch (JsonProcessingException jpe)
        {
            System.err.println("INTERNAL: A JsonProcessingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
            return null;
        }

    }


    protected Vector<Pattern> patterns = null;		/**< local singleton array accessed from patterns() */
    public Vector<Pattern> patterns()
    {
        if (null == patterns) patterns = new Vector<Pattern>();    /**< singleton access for patterns @return collection of patterns */
        return patterns;
    }

    protected TreeMap<String,Entity> entities = null;		/**< local singleton array accessed from entities() */
    public TreeMap<String,Entity> entities()
    {
        if (null == entities) entities = new TreeMap<String,Entity>();    /**< singleton access for entities @return collection of entities */
        return entities;
    }

    protected WWNDescription wwndesc = null;		/**< local singleton array accessed from wwndesc() */
    public WWNDescription wwndesc()
    {
        if (null == wwndesc) wwndesc = new WWNDescription();    /**< singleton access for wwndesc @return wwndesc */
        return wwndesc;
    }

    /**
     * Absorb a pattern for chunking together nickname patterns and execute it
     * immediately on all current orphan LeafEntities.
     *
     * The pattern given will be absorbed for the side-benefit of a user testing
     * patterns against names using the --checkpattern option.  The pattern is also
     * immediately executed, such that the following four cases occur for each orphan
     * entity evaluated:
     *
     * - the resulting name is not an entity that exists in the permanent nor hold space; create a hold-space entity which adopts this orphan
     * - the resulting name is an entity which does adopt this orphan; orphan is adopted by named entity
     * - the resulting name is an entity which does not adopt this orphan; entity does not adopt this one nor does a new entity get created in hold space
     * - the resulting name matches the current orphan entity; create a hold-space entity which adopts this orphan and suffixes its name
     *
     * When complete, the "hold" space is evaluated to remove any "parents" for which
     * there is only one child, thus eliminating lame pattern results before any next
     * run
     *
     * @param pattern a String pattern to execute and absorb (into an internal array for use later)
     */
    void absorbPattern (String pattern)
    {
        boolean verbose = new Boolean (System.getProperties().getProperty("debug.showPattern"));
        Entity wk;
        Entity parent;
        Pattern p = Pattern.compile(pattern);

        if (verbose) System.out.println("absorbing pattern: "+pattern);
        /* absorb for --checkpattern behavior */
        patterns().add(p);

        TreeMap<String,Entity> holdspace = new TreeMap<String,Entity>();

        for (String s: entities().keySet())
            if (null != (wk = entities().get(s)))
                if (wk instanceof Entity.LeafEntity)
                {
                    Entity.LeafEntity work = (Entity.LeafEntity) wk;
                    if ( (null == work.parent) || (null == work.parent.get()) )
                    {
                        if (verbose) System.out.println("Analyzing "+work.name()+" with "+pattern);
                        java.util.regex.Matcher m = p.matcher(work.name());
                        if (m.find())
                        {
                            String possibleName = m.group(1);
                            if (verbose) System.out.println("Analyzing "+work.name()+" with "+pattern+" possible: "+possibleName);

                            /* OK, orphan.  Which of the four cases are we? */
                            if ( (null != (parent = entities.get(possibleName))) || (null != (parent = holdspace.get(possibleName))) )
                            {
                                if (verbose) System.out.println("Case 2/3 "+work.name()+" with "+pattern+" possible: "+possibleName+" parent is a "+parent.getClass().getName().replaceAll(".*\\.",""));
                                /* case 2 & 3: possibly adopt this entity, blindly ignoring if the parent refuses */
                                try
                                {
                                    parent.maybeAdopt(work);
                                }
                                catch (Entity.ImproperChildException ice)
                                {
                                    if (verbose) System.out.println("Case 2/3 "+work.name()+" with "+pattern+" possible: "+possibleName+" parent is a "+parent.getClass().getName().replaceAll(".*\\.","")+" refused adoption");
                                    /* ignored - same action either way */
                                }
                            }
                            else if (possibleName.equalsIgnoreCase(work.name()))
                            {
                                if (verbose) System.out.println("Case 4 "+work.name()+" with "+pattern+" possible: "+possibleName);
                                /* case 4: parent matches.  need to rename this one and adopt into a new parent */
                                String wwn = work.wwn;

                                if (
                                    (null == entities().get(work.name()+"_"+wwn.substring(wwn.length()-4)))
                                    &&
                                    (null == holdspace.get(work.name()+"_"+wwn.substring(wwn.length()-4)))
                                )
                                {
                                    work.setname(work.name()+"_"+wwn.substring(wwn.length()-4));
                                    entities().put(work.name(), entities().remove(possibleName));
                                    holdspace.put (possibleName, work.newParent(possibleName));
                                }
                                else if (
                                    (null == entities().get(String.format("%s_%05d",work.name(), wwn.hashCode())))
                                    &&
                                    (null == holdspace.get(String.format("%s_%05d",work.name(), wwn.hashCode())))
                                )
                                {
                                    work.setname(String.format("%s_%05d",work.name(), wwn.hashCode()));
                                    entities().put(work.name(), entities().remove(possibleName));
                                    holdspace.put (possibleName, work.newParent(possibleName));
                                }
                            }
                            else
                            {
                                if (verbose) System.out.println("Case 1 "+work.name()+" with "+pattern+" possible: "+possibleName);
                                /* case 1: no entity found; create in hold */
                                holdspace.put (possibleName, work.newParent(possibleName));
                            }
                        }
                    }
                }
                else
                {
                    if (verbose) System.out.println("skipping "+wk.name()+" a "+wk.getClass().getName());
                }
            else
            {
                if (verbose) System.out.println("get of "+s+" failed");
            }


        /* complete: nuke any single-child parents */
        Vector<String>nukeList = new Vector<String>();
        for (String s: holdspace.keySet())
            if (null != (wk = holdspace.get(s)))
            {
                if (verbose) System.out.println("nukecheck: "+wk.name()+" has "+wk.children().size()+" children");
                if (wk.children().size() < 2)
                    nukeList.add(s);
            }

        for (String s: nukeList)
        {
            if (verbose) System.out.println("removing single-child pattern-merge entity: "+s);
            holdspace.remove (s);
        }

        /* now shift the remainders over to permanent store */
        for (String s: holdspace.keySet())
            if (null != (wk = holdspace.get(s)))
            {
                if (verbose) System.out.println("moving: "+s);
                entities.put (s, wk);
            }

        if (verbose)
        {
            System.out.println("finally after executing pattern \""+pattern+"\":");
            for (String s: entities.keySet()) System.out.println("entity: "+s);
        }
    }

    /**
     * Exercise all current chunking patterns against a given nickname.  Given a string
     * assumed to be a hostname or alias, all patterns currently absorbed will be
     * exercised to show the possible results in order they would be attempted.  This
     * is intended to allow in-situ pattern editing and verification rather than
     * perfect knowledge of the regex system used.
     *
     * As is assumed in the VW4 product, the regex is performed as:   s/{pattern}/\1/
     * such that for a given pattern, the first capturing group is the result
     * For example, given a pattern of "^(.*).{5}$", the ".{5}$" matches the final 5
     * characters (5 wildcards before end-of-line), leaving the remainder within
     * "^(.*)".  All but the final 5 characters are contained in that capture-grouping,
     * so the result is all but the final 5 characters.
     *
     * param alias a String nickname to exercise all patterns against
     */
    String[] exercisePattern (String alias)
    {
        String r[] = new String[patterns().size()];
        int rc = 0;

        for (Pattern p: patterns())
            try
            {
                java.util.regex.Matcher m = p.matcher(alias);
                if (m.find())
                {
                    if (true == new Boolean (System.getProperties().getProperty("debug.showPattern")))
                        for (int i = 0; i <= m.groupCount(); i++)
                            System.out.println("match alias "+alias+" with "+p.toString()+" match #"+i+" --> "+m.group(i));

                    r[rc++] = m.group(1);
                }
                else
                    r[rc++] = alias;
            }
            catch (java.lang.IllegalStateException ise)
            {
                r[rc++] = alias;
                System.out.println("Internal Error: ISE during match.  Skipping "+p.toString()+" with "+alias);
            }

        return r;
    }

    Entity entityAccepting (Entity newguy)
    {
        return null;
    }


    public static String report (int orphans, int fostered, int total)
    {
        return String.format("%5d total entities\n%5d leaf nodes\n%5d orphans\n%5.2f %% coverage", total, (orphans + fostered), orphans, (fostered * 100.0)/(orphans + fostered));
    }


    void report ()
    {
        int orphans = 0;
        int fostered = 0;
        int total = 0;
        Entity e;

        for (String s: entities().keySet())
            if ( (null != s) && (null != (e = entities().get(s))) )
            {
                total++;

                if (e instanceof Entity.LeafEntity)
                {
                    if (e.isOrphan()) orphans++;
                    else fostered++;
                }
            }

        System.out.println("@PACKAGE@ @VERSION@-@BUILDID@");
        System.out.println(report (orphans, fostered, total));
    }


    /**
     * one-shot load a new file and remove the contents from the internal list of leafEntities (HBAs, FAs)
     *
     * Working on only the leaf entities, this uses the parser array to parse an input stream,
     * and for each WWPN found, it removes that leaf entity from the system.  It doesn't affect
     * the child_entities of referring entities to allow for a loaded entity list to still
     * refer to entities which are already on the target system.
     *
     * @param f name of file to open
     *
     * @see https://github.com/chickenandpork/fibrechannel-parsers/
     */
    protected void loadAndRemoveFile(String f)
    {
        ZoneParser p = null;
        java.util.Properties prop = new java.util.Properties();

        for (int x = 3; (0 < x ) && (null == (p = FCParser.loadFile(FCParser.openSource(f, /* FCParser verbose */ true, prop), "@PACKAGE@", /* ZParser(s) verbose */ true, prop) )); x--)
            System.out.println("retrying: reading "+f);

        /*
         * iteratively search all entities for WWNs becomes a O(N^2) because the entities are
             * not sorted/indexed by WWPN.  For that reason, we're going to iterate the entities, using
             * a hashmap of the WWPNs for removal to accelerate the search to a O(N * log2(N))
             */

        TreeSet<String> removals = new TreeSet<String> ();
        Vector<String>postRemovals = new Vector<String>();
        String wwns[];

        if (null != p) for (ZPAliasEntry zpa: p.aliasArray())
                if ( (null != zpa) && (null != (wwns = (zpa.getWWNArray()))) )
                    for (String wwn: wwns)
                        if (null != wwn)
                            removals.add(wwn);

        /*
             * That was weird, and should @todo be converted to using the remove() operator of an iterator; alternatively, navigableKeySet() might give enough nav/removal.
             *
             * now that removals is loaded up, removals.contains(WWN) means "we need to nuke that entity".
             * Unfortunately, to avoid a concurrent mod exception, we merely increment the counter in
             * the TreeMap, them post-process the TreeMap.  Seems kinda dumb, but avoids segv, which
             * makes it a bit cooler
             */
        for (String name: entities.keySet())
        {
            Entity e = entities.get(name);

            if
            (
                (e instanceof Entity.LeafEntity)
                &
                ( removals.contains(((Entity.LeafEntity) e).wwn()) )
            )
                postRemovals.add(name);
        }

        /* now, finally, post-process the postRemovals as removals */
        for (String name: postRemovals.toArray(new String[0]))
        {
            entities.remove(name);
        }

    }


    /**
     * one-shot load a new file and absorb the contents: open the file and stream the
     * contents at an array of parsers, the one with the best results wins; using that
     * result, absorb all alias information, attempting to create parent
     * storagecontroller(s) or hosts as resulting from absorbtion patterns
     *
     * @param f name of file to open
     *
     * @see https://github.com/chickenandpork/fibrechannel-parsers/
     */
    protected void loadAndAbsorbFile(String f)
    {
        ZoneParser p = null;
        java.util.Properties prop = new java.util.Properties();

        for (int x = 3; (0 < x ) && (null == (p = FCParser.loadFile(FCParser.openSource(f, /* FCParser verbose */ true, prop), "@PACKAGE@", /* ZParser(s) verbose */ true, prop) )); x--)
            System.out.println("retrying: reading "+f);

        Entity e = null;
        String[] wwns = null;

        if (null != p) for (ZPAliasEntry zpa: p.aliasArray())
                if ( (null != zpa) && (null != (wwns = (zpa.getWWNArray()))) )
                {
                    boolean dupes = (1 < wwns.length);
                    if (null != zpa) for (String wwn: zpa.getWWNArray())
                        {
//WWNDesc w = wwndesc().getWWNDescriptor(wwn, false, DevRole.max()-1);
//System.out.println("wwn: "+wwn+" (of "+wwns.length+" name: "+zpa.name()+" desc: "+(null == w ? "null" : w.getClass().getName()));

                            boolean bogus =  zpa.name().matches("[0-9a-fA-F]{16}") || zpa.name().matches("0x[0-9a-fA-F]{5,6}");

                            Entity newguy;
                            WWNDesc d = wwndesc().getWWNDescriptor(wwn, false, DevRole.max()-1);
                            if (null == d)
                                newguy = new EntityHBA (zpa.name(), wwn);
                            else if (d instanceof WWNDescTarget)
                                newguy = new EntityFA (bogus?d.toString() :( zpa.name()+(dupes?(null==d.descPort()?"":"-"+d.descPort()) :"")), wwn);
                            else if (d instanceof WWNDescSwitch)
                                /* assume a switch device is actually a NPIV virtualizing hosts */
                                newguy = new EntityHBA (bogus?d.toString() :( zpa.name()+(dupes?(null==d.descPort()?"":"-"+d.descPort()) :"")), wwn);
                            else
                                newguy = new EntityHBA (bogus?d.toString() :( zpa.name()+(dupes?(null==d.descPort()?"":"-"+d.descPort()) :"")), wwn);

                            newguy.setDescription (wwn+","+zpa.name()+" converted via "+p.getClass().getName().replaceAll("^.*\\.","")+" from "+f);

                            if (null != (e = entityAccepting(newguy)))
                                System.out.println("object "+e.toString()+" accepts "+wwn+", "+zpa.name());

                            if (null == entities().get(newguy.name()))
                                entities().put(newguy.name(), newguy);
                            else if (null == entities().get(newguy.name()+"_"+wwn.substring(wwn.length()-4)))
                            {
                                newguy.setname(newguy.name()+"_"+wwn.substring(wwn.length()-4));
                                entities().put(newguy.name(), newguy);
                            }
                            else if (null == entities().get(String.format("%s_%05d",newguy.name(), wwn.hashCode())))
                            {
                                newguy.setname(String.format("%s_%05d",newguy.name(), wwn.hashCode()));
                                entities().put(newguy.name(), newguy);
                            }
                            //ports.put(wwn.toLowerCase().replaceAll("[^a-f0-9]",""), zpa.name().replaceAll("\"",""));
                        }
                }
    }

    /** simple convenience interface to allow entity selection to be codified and created on-the-fly in a query API */
    public interface EntitySelector
    {
        /**
         * function to define whether an entity should be selected based on its attributes
         *
         * @param e entity to consider
         * @return true if this entity satisfies the coded logic
         */
        public boolean select(Entity e);
    }

    /**
     * Write an output file, finalizing from entities() if required
     *
     * @param filename name of file to write
     */
    void writeOutputfile(String filename)
    {
        /*
           XmlMapper mapper = new XmlMapper()
           MyBean bean = new MyBean();

           String xml = mapper.writeValueAsString(bean);
           // System.out.println(mapper.writerWithDefaultPrettyPrinter().writeValueAsString(user));

           // we get something like "<MyBean><property>value</property>....</MyBean>"
           MyBean beanFromXml = mapper.readValue(xml, MyBean.class);
         */


        try
        {
            if ( (null != filename) && (filename.equalsIgnoreCase("schema.json")) )
            {
                com.fasterxml.jackson.databind.ObjectMapper mapper = new com.fasterxml.jackson.databind.ObjectMapper();
                JsonSchema schema = mapper.generateJsonSchema(vwimport.getClass());


                //ObjectWriter ow = mapper.writer().withDefaultPrettyPrinter();
                /*
                ObjectWriter ow = mapper.writer(new com.fasterxml.jackson.core.util.DefaultPrettyPrinter());
                	System.out.println(ow.writeValueAsString(schema)); */
                System.out.println(prettyJSON(vwimport));

                //System.out.println(mapper.writer(new com.fasterxml.jackson.core.util.DefaultPrettyPrinter()).writeValueAsString(schema));
            }
            else if ( (null != filename) && (filename.equalsIgnoreCase("orderedtuples.csv")) )
            {
                System.out.println("writing ordered tuples to "+filename);
                try
                {
                    writeOrderedTuples(filename,null);
                }
                catch (java.io.IOException ioe)
                {
                    System.out.println("IO Exception writing to "+filename+": "+ioe.getMessage());
                }
            }
            else if ( (null != filename) && (filename.equalsIgnoreCase("orphanentities.csv")) )
            {
                System.out.println("writing ordered tuples to "+filename);
                try
                {
                    writeOrderedTuples(filename, new EntitySelector()
                    {
                        public boolean select(Entity e)
                        {
                            return e.isOrphan();
                        }
                    });
                }
                catch (java.io.IOException ioe)
                {
                    System.out.println("IO Exception writing to "+filename+": "+ioe.getMessage());
                }
            }
            else if ( (0 == finalizeEntities()) && (null == vwimport) )
            {
                System.err.println("ERROR: no content loaded (finalized)");
                return;
            }
            else if (
                ( null == filename ) ||
                (filename.equalsIgnoreCase("")) ||
                (filename.equalsIgnoreCase("-"))  )
            {
                System.err.println("NOTE: writing to stdout");
                String o = (new com.fasterxml.jackson.databind.ObjectMapper()).writerWithDefaultPrettyPrinter().writeValueAsString(vwimport);
                System.out.println(o);
            }
            else
            {
                com.fasterxml.jackson.databind.ObjectMapper mapper = new com.fasterxml.jackson.databind.ObjectMapper();
                try
                {
                    mapper.writerWithDefaultPrettyPrinter().writeValue(new File(filename), vwimport);
                }
                catch (java.io.IOException ioe)
                {
                    System.out.println("IO Exception writing to "+filename+": "+ioe.getMessage());
                }
                //JsonParseException,
                //JsonMappingException
            }
        }
        catch (JsonMappingException jme)
        {
            System.err.println("INTERNAL: A JsonMappingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
            System.out.println(jme.getMessage());
        }
        catch (JsonProcessingException jpe)
        {
            System.err.println("INTERNAL: A JsonProcessingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
        }
    }

    /**
     * Finalize absorbed Entities: for each entity, transfer from structured tree of Entities to vwimport array for writing
     *
     * @return number of items finalized
     */
    int finalizeEntities()
    {
        Entity e;
        int i = 0;

        for (String s: entities().keySet())
            if ( (null != s) && (null != (e = entities().get(s))) )
                if (e.isOrphan())	/* tree-order transversal: having a parent means this entity will be written when the parent writes */
                    i += e.addTo(vwimport(), "@PACKAGE@-@VERSION@-@BUILDID@");

        //System.out.println("transferred "+i+" entities from "+entities().size()+" entities, resulting in "+vwimport().entities().size()+" json entities");

        return i;
    }


    /**
     * Export an "OrderedTuples.csv" file as a stopgap measure until proper JSON processing can be completed
     *
     * @param name filename to write
     * @param sel an optional selector-method
     * @throws java.io.IOException when PrintStream throws an exception
     */
    void writeOrderedTuples(String name, EntitySelector sel) throws java.io.IOException
    {
        PrintStream fos = new PrintStream(name);

        Entity e;

        for (String s: entities().keySet())
            if (null != (e = entities.get(s)))
                if ( (null == sel ) || (sel.select(e)) )
                {
                    /* could be handled as merely (instanceof LeafEntity) but still need to print host/array text, more clear to keep separate */
                    if (e instanceof EntityHBA)
                    {
                        EntityHBA h = (EntityHBA) e;

                        /* name,type,WWPN[,customname] */
                        fos.println(String.format("%s,%s,%s,%s",h.parentName(),"host",h.wwn(),h.name()));
                    }
                    else if (e instanceof EntityFA)
                    {
                        EntityFA h = (EntityFA) e;

                        /* name,type,WWPN[,customname] */
                        fos.println(String.format("%s,%s,%s,%s",h.parentName(),"array",h.wwn(),h.name()));
                    }
                }
    }


    /**
     * Usage messages are useful to those of us with short memories as well (hey, I just need to add swap!)
     *
     * @param progname the name of the program (args[0]) to print on a usage message
     */
    void usage(String progname)
    {
        System.out.println("Usage: "+progname+" -V|--version|-H|--help");
        System.out.println("     : "+progname+" --read <filename>|--input <filename> | -r <filename> | -i <filename>");
        System.out.println("     : "+progname+" --nickname=<filename>|-N<filename> | --removenicknames=<filename> | -i <filename>");
        System.out.println("     : "+progname+" --pattern=<pattern>|-P <pattern> [--pattern=...] --checkpattern=<alias>");

        System.out.println("   ie: "+progname+" --read import.json");
        System.out.println("       "+progname+" -r import.json");
        System.out.println("       "+progname+" -N somenicknames.csv -R existing.csv -o OrderedTuples.csv");
        System.out.println("       "+progname+" -N somenicknames.csv -R existing.csv --pattern=\"^([^-]+)-.*\" --report -o OrderedTuples.csv -o OrphanEntities.csv");

        System.out.println("\nA possible workflow could be:");
        System.out.println("1. collect all the text content: nickname=");
        System.out.println("       "+progname+" -N somenicknames.csv -N morenicknames.dad -N andzones.zoneshow");
        System.out.println("2. see how it looks: report");
        System.out.println("       "+progname+" -N somenicknames.csv -N morenicknames.dad -N andzones.zoneshow --report");
        System.out.println("3. check out a pattern to see if it collects nicknames correctly: pattern=, checkpattern=");
        System.out.println("       "+progname+" -P \"^(.*)_FC(\\d)$\" -p \"server12_FC2\" -p \"server12_FC1\" -p \"server11_FC1\"");
        System.out.println("\"server12_FC2\" --> \"server12\"\n\"server12_FC1\" --> \"server12\"\n\"server11_FC1\" --> \"server11\"\n so this looks like two HBAs for server12, one for server11.  ok");
        System.out.println("4. add the pattern, see how it looks: report");
        System.out.println("       "+progname+" -N somenicknames.csv -N morenicknames.dad -N andzones.zoneshow --pattern=\"^(.*)_FC(\\d)$\" --report");
        System.out.println(report (14, 33, 1011));
        System.out.println("5. write it out to JSON");
        System.out.println("       "+progname+" -N somenicknames.csv -N morenicknames.dad -N andzones.zoneshow --pattern=\"^(.*)_FC(\\d)$\" -o customer.json");
        System.out.println("6. try importing it; there are typically Invalid Entities (Orphans), save that error message\nie: saved as \"invalid.txt\"");
        System.out.println("       "+progname+" -N somenicknames.csv -N morenicknames.dad -N andzones.zoneshow --pattern=\"^(.*)_FC(\\d)$\" -R invalid.txt -o customer.json");
        System.out.println("7. try importing it again.  A single WWN is bad?  write that to another file, exclude, and try a new JSON:");
	System.out.println("       echo '10000000c9123456,\"serverc9123456\"' > manualskip.txt");
        System.out.println("       "+progname+" -N somenicknames.csv -N morenicknames.dad -N andzones.zoneshow --pattern=\"^(.*)_FC(\\d)$\" -R invalid.txt -R manualskip.txt -o customer.json");
    }


    /**
     * Main function, as you can tell.
     *
     * this function merely parses the command-line to dispatch actions to the meat of the meal above.
     * I'm using an actual GetOpt because, yes, I'm a UNIX/C hack, re-using 3-decades-old knowledge,
     * but this also preserves both extensibility and the ability to use longopts in scripts as a
     * way to self-document what the tool's doing.
     *
     * No real intelligence herein except the parse-and-redirect action.
     *
     * @param args as you'd expect, these are commandline arguments given when the jar is activated
     */
    public static void main(String args[])
    {
        VirtualWisdom4ClientTool m = new VirtualWisdom4ClientTool();

        Vector<LongOpt> options = new Vector(20,2);

        /**
         * Always always ALWAYS provide a quick reference and a version output
         *
         * @cmdopt -H|--help Show a simple help screen as a reminder of options which are understood by the application
         * @cmdopt @code java -jar @PACKAGE@.jar --help @endcode
         *
         * @cmdopt -V|--version Show the current release version for reference
         * @cmdopt @code java -jar @PACKAGE@.jar --version
         *  @VERSION@-@BUILDID@ @endcode
         *
         * @cmdopt -n|--nicknameout={file} Output nicknames from internal store
         * @cmdopt -o|--output={file} Output nicknames from internal store
        * --nicknameout and --output are currently functionally identical; they both cause the internal nickname/entity base to be written out as JSON with the exception of a few "magic" filenames:
         *
         * @cmdopt 1. <b>schema.json</b> will cause the current schema to be written
         * @cmdopt 2. <b>orderedtuples.csv</b> will cause an OrderedTuples.csv file to be written, suitable for post-processing via csv-to-json.awk but allowing a user to more easily edit CSV for fine-tuning
         * @cmdopt 3. <b>orphanentities.csv</b> will cause a CSV to be written listing all orphan entities.  An "Orphan Entity" is an entity lacking a parent entity, such as an "HBA Port" without a "host" parent, or a "iomodule" without a parent "storagearray" entity.
         *
         * @cmdopt All other filename patterns will result in a JSON-formatted file
         *
               * @cmdopt -N|--nickname={file/uri} Import nicknames by parsing a text stream from various sources
               * @cmdopt @code java -jar @PACKAGE@.jar --nickname=switch44.zoneshow
               * Parse results for AliShowZoneParser:
               * Zones: 44
               * Aliases: 112 (names with one or more WWPNs)
               * Aliases: 136 (name/WWPN tuples) @endcode
               * In this example, a zone file was parsed by the AliShowZoneParser resulting in 112
               * nicknames; due to duplicate nicknames, there are actually 136 unique WWPN/alias
               * tuples, which means that (136-112) 24 of the WWPNs have the same alias as other
               * WWPNs
               *
               * @cmdopt -i|--input import an existing JSON file for later editing
               * @cmdopt -r|--read import an existing JSON file for later editing
               * @cmdopt @code java -jar @PACKAGE@.jar --read working.json @endcode
               *
               * @cmdopt -R|--remove Parse ncknames for removal from the internal nickname list
               * @cmdopt -R|--removenicknames Parse ncknames for removal from the internal nickname list
               *
               * @cmdopt -!|--report Summarize the current status of the internal nicknaes and pattern/collation coverage
               * @cmdopt @code java -jar @PACKAGE@.jar --nickname=switch44.zoneshow  --report
         * (@PACKAGE@) parsed 0 zones, 2 aliases via Alias4Parser
         * @PACKAGE@ @VERSION@-@BUILDID@
         *     5 total entities
         *     4 leaf nodes
         *     2 orphans
         * 50.00 % coverage @endcode
               */

        options.add(new LongOpt("help", LongOpt.NO_ARGUMENT, null, 'H'));
        options.add(new LongOpt("version", LongOpt.NO_ARGUMENT, null, 'V'));

        options.add(new LongOpt("read", LongOpt.REQUIRED_ARGUMENT, null, 'r'));
        options.add(new LongOpt("input", LongOpt.REQUIRED_ARGUMENT, null, 'i'));
        options.add(new LongOpt("nickname", LongOpt.REQUIRED_ARGUMENT, null, 'N'));
        options.add(new LongOpt("remove", LongOpt.REQUIRED_ARGUMENT, null, 'R'));
        options.add(new LongOpt("removenicknames", LongOpt.REQUIRED_ARGUMENT, null, 'R'));
        options.add(new LongOpt("report", LongOpt.NO_ARGUMENT, null, '!'));
        options.add(new LongOpt("nicknameout", LongOpt.REQUIRED_ARGUMENT, null, 'n'));
        options.add(new LongOpt("output", LongOpt.REQUIRED_ARGUMENT, null, 'o'));
        options.add(new LongOpt("pattern", LongOpt.REQUIRED_ARGUMENT, null, 'P'));
        options.add(new LongOpt("checkpattern", LongOpt.REQUIRED_ARGUMENT, null, 'p'));

        options.add(new LongOpt("test", LongOpt.REQUIRED_ARGUMENT, null, 'T'));

        /* *@DO_GETOPTJAR_TRUE@/        org.smallfoot.getopt.GetOpt	g = new org.smallfoot.getopt.GetOpt("vw4tool", args, options);        /@DO_GETOPTJAR_TRUE@* */
        /* *@DO_GETOPTJAR_FALSE@/       gnu.getopt.Getopt		g = new gnu.getopt.Getopt("vw4tool", args, "HVR:r:i:N:n:o::P:p:T:", options.toArray(new LongOpt[0]));        /@DO_GETOPTJAR_FALSE@* */

        int c;
        while ((c = g.getopt()) != -1)
        {
            switch(c)
            {
            case 'i':	/* fall-thru */
            case 'r':   // Read in a config file
            {
                m.load(g.getOptarg());
            }
            break;

            /**
             * @cmdopt -P|--pattern= is used to provide an "aggregating pattern" to collect Orphan Entities into a container.  An "Orphan Entity" is an entity which is not part of a larger device: an HBA not assigned to a host, or a FA not assigned to a storage array.  Aggregating Patterns are evaluated immediately, so their order amidst other command options to import or remove entities is important.
             */
            case 'P': /* input chunking-pattern for host-combination and storage-combination */
                m.absorbPattern(g.getOptarg());
                break;

            /**
             * @cmdopt -p|--checkpattern= is used to test an "aggregating pattern" against a certain nickname/alias.  Although Aggregating Patterns are evaluated immediately, they're stored for testing as well, so even though we're giving a test alias after the pattern, it'll evaluate all loaded patterns against the alias:
             * @cmdopt @code java -jar @PACKAGE@.jar --pattern="([^-]+)-[^-]+$" --checkpattern=NetApp-123456 --checkpattern=UberServer_44_HBA0
	     * "NetApp-123456" --> "NetApp"
	     * "UberServer_44_HBA0" --> "UberServer_44_HBA0" @endcode
	     * @cmdopt in this example, the one pattern it tested against a new alias when the --checkpattern is encountered; if there were two patterns, each pattern would be tried to the checkpattern sample when seen:
	     *
             * @cmdopt @code java -jar @PACKAGE@.jar --pattern="([^-]+)-[^-]+$" --pattern="^(.*)_hba(\d+)$" --checkpattern=NetApp-123456 --checkpattern=UberServer_44_hba0
	     * "NetApp-123456" --> "NetApp"
	     * "NetApp-123456" --> "NetApp-123456"
	     * "UberServer_44_HBA0" --> "UberServer_44_hba0"
	     * "UberServer_44_HBA0" --> "UberServer_44" @endcode
	     * @cmdopt in this example, two patterns ( "([^-]+)-[^-]+$" and "^(.*)_hba(\d+)$" ) are loaded; when "NetApp-123456" is given as a checkpattern, each is tried in turn, so we see that "([^-]+)-[^-]+$" converts "NetApp-123456" to "NetApp", which means a bunch of devices "NetApp-123456", "NetApp-123457", "NetApp-ABCDEF" would be child entities of a larger entity "NetApp".  In essence, all the NetApp-* are collected into the same contailer called "NetApp".  Similarly, "([^-]+)-[^-]+$" and "^(.*)_hba(\d+)$" are tested against "UberServer_44_hba0" when the checkpattern is given, and we can see that "([^-]+)-[^-]+$" makes no difference to the value, but "^(.*)_hba(\d+)$" has the desired effect of chopping off the "_hba#" portion.
	     */
            case 'p': /* exercise chunking-pattern for given alias */
                for (String s: m.exercisePattern(g.getOptarg()))
                    if (null != s)
                        System.out.println("\""+g.getOptarg()+"\" --> \""+s+"\"");
                break;

            case 'N': /* input Nicknames using file://, ftp://, http:// via fibrechannel-parsers fcparsers.jar */
                m.loadAndAbsorbFile(g.getOptarg());
                break;

            case 'R': /* read a list of Nicknames for removal using file://, ftp://, http:// via fibrechannel-parsers fcparsers.jar */
                m.loadAndRemoveFile(g.getOptarg());
                break;

            case '!': /* report */
                m.report();
                break;



            case 'n': /* output Nicknames as Entities to the given file */
            /* fall-thru */
            case 'o':   // Write a config file out
            {
                m.writeOutputfile(g.getOptarg());
            }
            break;

            /*
             * Testcase generation -- internal use only, used to create bogus internal content to test output format
             */
            case 'T':   // create internal content for export
            {
                if (g.getOptarg().equalsIgnoreCase ("sample01"))
                {
                    VWImport vwimport = new VWImport();
                    VWImport.Entity e = new VWImport.Entity();
                    e.description = "sample01 test entity";
                    e.edit_type = VWImport.Edit_Type.add;
                    e.type = "application";
                    e.name = "sample01_itl";
                    e.itl_patterns = new Vector<VWImport.ITLPattern>();
                    VWImport.ITLPattern i = new VWImport.ITLPattern();
                    i.edit_type = VWImport.Edit_Type.add;
                    i.initiator = "1000002590123456";
                    e.itl_patterns.add(i);
                    vwimport.entities().add(e);
                    System.err.println(vwimport.entities().size() + " entities defined");

                    m.vwimport = vwimport;
                }
                else if (g.getOptarg().equalsIgnoreCase ("sample02"))
                {
                    Entity n = new EntityFA ("sample_02", "10000000c9123456");
                    n.description = "sample02 test FA";
                    m.entities().put(n.name(), n);
                }
                else if (g.getOptarg().equalsIgnoreCase ("sample03"))
                {
                    Entity n = new EntityFA ("NetApp 01 A", "500a098598123456");
                    n.description = "sample03 test NetApp";
                    m.entities().put(n.name(), n);

                    n = new EntityFA ("NetApp 01 B", "500a098698123456");
                    n.description = "sample03 test NetApp";
                    m.entities().put(n.name(), n);

                    n = new EntityHBA ("hba 02 A", "10000000c9123456");
                    n.description = "sample03 test HBA";
                    m.entities().put(n.name(), n);

                    n = new EntityHBA ("hba 02 B", "10000000c9123457");
                    n.description = "sample03 test HBA";
                    m.entities().put(n.name(), n);
                }
                else
                {
                    System.err.println("testcase generation: Testcase \""+g.getOptarg()+"\" is not understood");
                    System.err.println("testcases include: sample01, sample02");
                    return;
                }
            }
            break;

            /*
             * Follows is the "house-keeping": versions, usage, and the catch-all for bad options.
             */
            case 'V':   // print the version and quit
            {
                /* *@DO_GETOPTJAR_FALSE@/ System.out.println("@VERSION@-@BUILDID@"); /@DO_GETOPTJAR_FALSE@* */
                /* *@DO_GETOPTJAR_TRUE@/ System.out.println(g.consistentVersion("@VERSION@-@BUILDID@")); /@DO_GETOPTJAR_TRUE@* */
                return;
            }

            default:
            case '?':
            case 'H':
                /* *@DO_GETOPTJAR_FALSE@/ m.usage("vw4tool"); /@DO_GETOPTJAR_FALSE@* */
                /* *@DO_GETOPTJAR_TRUE@/ m.usage(g.progname()); /@DO_GETOPTJAR_TRUE@* */
                break;
            }
        }
    }
}
