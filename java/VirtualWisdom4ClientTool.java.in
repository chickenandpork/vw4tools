package org.smallfoot.vw4 ;

/** @file */

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.PrintStream;
import java.util.Vector;
import java.util.TreeMap;
import java.util.TreeSet;
import java.util.regex.Pattern;
import javax.activation.DataSource;
import javax.activation.URLDataSource;
import javax.xml.XMLConstants;
import javax.xml.namespace.QName;
import javax.xml.xpath.XPath;
import javax.xml.xpath.XPathExpression;
import javax.xml.xpath.XPathFactory;
import gnu.getopt.Getopt;
import gnu.getopt.LongOpt;
import org.smallfoot.parser.FCParser;
import org.smallfoot.parser.zone.ZPAliasEntry;
import org.smallfoot.parser.zone.ZoneParser;
import org.smallfoot.vw4.VWImport;
import org.smallfoot.wwn.DevRole;
import org.smallfoot.wwn.WWNDesc;
import org.smallfoot.wwn.WWNDesc.WWNDescSwitch;
import org.smallfoot.wwn.WWNDesc.WWNDescTarget;
import org.smallfoot.wwn.WWNDescription;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;


/* The following is conditionally permitted based on the mutually-exclusive choice at ./configure time.  --with-json= chooses exactly one of the following, causing one of the following comment blocks pairs to be butchered */
/* *@DO_JSON_JAVA_TRUE@/	import org.json.*;				/@DO_JSON_JAVA_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.core.json.*;	/@DO_JSON_JACKSON_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.core.*;		/@DO_JSON_JACKSON_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.databind.*;	/@DO_JSON_JACKSON_TRUE@* */
/* *@DO_JSON_JACKSON_TRUE@/	import com.fasterxml.jackson.databind.jsonschema.*;	/@DO_JSON_JACKSON_TRUE@* */

/**
 * VirtualWisdom4ClientTool is a "Swiss Army Knife" of tools used when working with
 * VirtualWisdom4.  The existence of these tools is not a judgement on VirtualWisdom4's
 * proper Engineering; rather, an acceptance that a faster-response solution for the
 * longer-tail of the normal curve is often helpful swapping QA delay for reduced customer
 * friction.
 *
 * As you'd expect, there is no support for this.  If it breaks, you may choose to keep both
 * pieces :)
 *
 * Ad-Hoc content for this utility-stack may appear at http://fcfae.com/
 */
public class VirtualWisdom4ClientTool
{
    private org.w3c.dom.Document xmlDocument;		/**< eventually used to hold an XML document when converting XML<-->JSON<-->XML */

    /**
     * Class Constructor to create with an initial file to load.
     *
     * @param xmlFile File to load at start
     *
     * @see #load(String)
     */
    public VirtualWisdom4ClientTool(String xmlFile)
    {
	this();
        load(xmlFile);
    }

    /**
     * Class Constructor with no initial file.
     */
    public VirtualWisdom4ClientTool()
    {
	FCParser.registerProtocols();
    }

    public VWImport vwimport = null;		/**< singleton list of JSON-writable objects accessed through vwimport() */
    protected VWImport vwimport()
    {
        if (null == vwimport) vwimport = new VWImport();    /**< singleton to access vwimport to allow for later post-process */
        return vwimport;
    }

    /**
     * Open a file.
     *
     * This is actually a wrapper for the underlying file load
     *
     * @param filename file to load
     * @throw IOException when File() encounters an error instaitating (typically path or permissions)
     */
    protected void _load(String filename)
    throws java.io.IOException
    {
        com.fasterxml.jackson.databind.ObjectMapper mapper = new com.fasterxml.jackson.databind.ObjectMapper();
        /** @todo: evaluate: mapper.configure(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES, false);  */

        vwimport = mapper.readValue(new File(filename), VWImport.class);
    }

    /**
     * Wrapper to just load the file, spitting out exceptions and stacks as they occur.
     *
     * @param filename file to load
     */
    public void load(String filename)
    {
        try
        {
            _load (filename);
        }
        catch (java.io.IOException ioe)
        {
            System.out.println("IO Exception reading from "+filename+": "+ioe.getMessage());
        }
        catch (java.lang.Exception e)
        {
            e.printStackTrace();
        }
    }

    /**
     * Save the current XML Document to a new file.
     *
     * @param filename filename to save into
     */
    protected void _save(String filename)
    throws java.lang.Exception
    {
        throw new java.lang.Exception ("unimplemented");
    }

    /**
     * Wrapper to just save the file, spitting out exceptions and stacks as they occur.
     *
     * @param filename filename to save into
     */
    public void save (String filename)
    {
        try
        {
            _save (filename);
        }
        catch (java.lang.Exception e)
        {
            e.printStackTrace();
        }
    }


    /**
     * Convenience function to generate a pretty-printed JSON text string
     *
     * @param v VWImport object to markup
     * @return a pretty-printed JSON using ObjectWriter.withDefaultPrettyPrinter() or null if an exception occurs
     */
    public String prettyJSON(VWImport v)
    {
        ObjectMapper mapper = new ObjectMapper();
        mapper.setSerializationInclusion(com.fasterxml.jackson.annotation.JsonInclude.Include.NON_NULL);

        try
        {
            ObjectWriter ow = mapper.writer().withDefaultPrettyPrinter();
            return ow.writeValueAsString(v);
        }
        catch (JsonMappingException jme)
        {
            System.err.println("INTERNAL: A JsonMappingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
            System.out.println(jme.getMessage());
            return null;
        }
        catch (JsonProcessingException jpe)
        {
            System.err.println("INTERNAL: A JsonProcessingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
            return null;
        }

    }


    protected Vector<Pattern> patterns = null;		/**< local singleton array accessed from patterns() */
    public Vector<Pattern> patterns()
    {
        if (null == patterns) patterns = new Vector<Pattern>();    /**< singleton access for patterns @return collection of patterns */
        return patterns;
    }

    protected TreeMap<String,Entity> entities = null;		/**< local singleton array accessed from entities() */
    public TreeMap<String,Entity> entities()
    {
        if (null == entities) entities = new TreeMap<String,Entity>();    /**< singleton access for entities @return collection of entities */
        return entities;
    }

    protected WWNDescription wwndesc = null;		/**< local singleton array accessed from wwndesc() */
    public WWNDescription wwndesc()
    {
        if (null == wwndesc) wwndesc = new WWNDescription();    /**< singleton access for wwndesc @return wwndesc */
        return wwndesc;
    }

    /**
     * Absorb a pattern for chunking together nickname patterns.  Hosts will absorb new
     * matches at a top-level (host->hba); storage will absorb a pattern by force into a
     * second-tier (storagearray -> storagecontroller).  This will let devices with
     * non-intuitive combinations (ie SVC nodes in an iogroup don't have any matching WWPN
     * parts).  Not sure how far this will snowball.
     *
     * param pattern a String pattern to absorb (into an internal array for use later)
     */
    void absorbPattern (String pattern)
    {
        patterns().add(Pattern.compile(pattern));
    }

    /**
     * Exercise all current chunking patterns against a given nickname.  Given a string
     * assumed to be a hostname or alias, all patterns currently absorbed will be
     * exercised to show the possible results in order they would be attempted.  This
     * is intended to allow in-situ pattern editing and verification rather than
     * perfect knowledge of the regex system used.
     *
     * As is assumed in the VW4 product, the regex is performed as:   s/{pattern}/\1/
     * such that for a given pattern, the first capturing group is the result
     * For example, given a pattern of "^(.*).{5}$", the ".{5}$" matches the final 5
     * characters (5 wildcards before end-of-line), leaving the remainder within
     * "^(.*)".  All but the final 5 characters are contained in that capture-grouping,
     * so the result is all but the final 5 characters.
     *
     * param alias a String nickname to exercise all patterns against
     */
    String[] exercisePattern (String alias)
    {
        String r[] = new String[patterns().size()];
        int rc = 0;

        for (Pattern p: patterns())
            try
            {
                java.util.regex.Matcher m = p.matcher(alias);
                if (m.find())
                {
                    if (true == new Boolean (System.getProperties().getProperty("debug.showPattern")))
                        for (int i = 0; i <= m.groupCount(); i++)
                            System.out.println("match alias "+alias+" with "+p.toString()+" match #"+i+" --> "+m.group(i));

                    r[rc++] = m.group(1);
                }
                else
                    r[rc++] = alias;
            }
            catch (java.lang.IllegalStateException ise)
            {
                r[rc++] = alias;
                System.out.println("Internal Error: ISE during match.  Skipping "+p.toString()+" with "+alias);
            }

        return r;
    }

    Entity entityAccepting (Entity newguy)
    {
        return null;
    }


    /**
     * one-shot load a new file and remove the contents from the internal list of leafEntities (HBAs, FAs)
     *
     * Working on only the leaf entities, this uses the parser array to parse an input stream,
     * and for each WWPN found, it removes that leaf entity from the system.  It doesn't affect
     * the child_entities of referring entities to allow for a loaded entity list to still
     * refer to entities which are already on the target system.
     *
     * @param f name of file to open
     *
     * @see https://github.com/chickenandpork/fibrechannel-parsers/
     */
    protected void loadAndRemoveFile(String f)
    {
        ZoneParser p = null;

        for (int x = 3; (0 < x ) && (null == (p = FCParser.loadFile(FCParser.openSource(f, /* FCParser verbose */ true), "@PACKAGE@", /* ZParser(s) verbose */ true) )); x--)
            System.out.println("retrying: reading "+f);

	/*
	 * iteratively search all entities for WWNs becomes a O(N^2) because the entities are
         * not sorted/indexed by WWPN.  For that reason, we're going to iterate the entities, using
         * a hashmap of the WWPNs for removal to accelerate the search to a O(N * log2(N))
         */

	TreeSet<String> removals = new TreeSet<String> ();
	Vector<String>postRemovals = new Vector<String>();
	String wwns[];

        if (null != p) for (ZPAliasEntry zpa: p.aliasArray())
	    if ( (null != zpa) && (null != (wwns = (zpa.getWWNArray()))) )
                for (String wwn: wwns)
		    if (null != wwn)
			removals.add(wwn);

	/*
         * now that removals is loaded up, removals.contains(WWN) means "we need to nuke that entity". 
         * Unfortunately, to avoid a concurrent mod exception, we merely increment the counter in
         * the TreeMap, them post-process the TreeMap.  Seems kinda dumb, but avoids segv, which
         * makes it a bit cooler
         */
	for (String name: entities.keySet())
	{
	    Entity e = entities.get(name);

	    if
	    (
		(e instanceof Entity.LeafEntity)
	    &
		( removals.contains(((Entity.LeafEntity) e).wwn()) )
	    )
		postRemovals.add(name);
	}

	/* now, finally, post-process the postRemovals as removals */
	for (String name: postRemovals.toArray(new String[0]))
	{
		entities.remove(name);
	}

    }


    /**
     * one-shot load a new file and absorb the contents: open the file and stream the
     * contents at an array of parsers, the one with the best results wins; using that
     * result, absorb all alias information, attempting to create parent
     * storagecontroller(s) or hosts as resulting from absorbtion patterns
     *
     * @param f name of file to open
     *
     * @see https://github.com/chickenandpork/fibrechannel-parsers/
     */
    protected void loadAndAbsorbFile(String f)
    {
        ZoneParser p = null;

        for (int x = 3; (0 < x ) && (null == (p = FCParser.loadFile(FCParser.openSource(f, /* FCParser verbose */ true), "@PACKAGE@", /* ZParser(s) verbose */ true) )); x--)
            System.out.println("retrying: reading "+f);

        Entity e = null;
	String[] wwns = null;

        if (null != p) for (ZPAliasEntry zpa: p.aliasArray())
	    if ( (null != zpa) && (null != (wwns = (zpa.getWWNArray()))) )
            {
                boolean dupes = (1 < wwns.length);
                if (null != zpa) for (String wwn: zpa.getWWNArray())
                    {
//WWNDesc w = wwndesc().getWWNDescriptor(wwn, false, DevRole.max()-1);
//System.out.println("wwn: "+wwn+" (of "+wwns.length+" name: "+zpa.name()+" desc: "+(null == w ? "null" : w.getClass().getName()));

			boolean bogus =  zpa.name().matches("[0-9a-fA-F]{16}") || zpa.name().matches("0x[0-9a-fA-F]{5,6}");

                        Entity newguy;
                        WWNDesc d = wwndesc().getWWNDescriptor(wwn, false, DevRole.max()-1);
                        if (null == d)
                            newguy = new EntityHBA (zpa.name(), wwn);
                        else if (d instanceof WWNDescTarget)
                            newguy = new EntityFA (bogus?d.toString() :( zpa.name()+(dupes?(null==d.descPort()?"":"-"+d.descPort()) :"")), wwn);
                        else if (d instanceof WWNDescSwitch)
                            /* assume a switch device is actually a NPIV virtualizing hosts */
                            newguy = new EntityHBA (bogus?d.toString() :( zpa.name()+(dupes?(null==d.descPort()?"":"-"+d.descPort()) :"")), wwn);
                        else
                            newguy = new EntityHBA (bogus?d.toString() :( zpa.name()+(dupes?(null==d.descPort()?"":"-"+d.descPort()) :"")), wwn);

                        newguy.setDescription (wwn+","+zpa.name()+" converted via "+p.getClass().getName().replaceAll("^.*\\.","")+" from "+f);

                        if (null != (e = entityAccepting(newguy)))
                            System.out.println("object "+e.toString()+" accepts "+wwn+", "+zpa.name());
                        else
                            for (Pattern s: patterns())
                                System.out.println("check pattern "+s+" for acceptance of "+wwn+", "+zpa.name());

                        if (null == entities().get(newguy.name()))
                            entities().put(newguy.name(), newguy);
                        else if (null == entities().get(newguy.name()+"_"+wwn.substring(wwn.length()-4)))
                        {
                            newguy.setname(newguy.name()+"_"+wwn.substring(wwn.length()-3));
                            entities().put(newguy.name(), newguy);
                        }
                        else if (null == entities().get(String.format("%s_%05d",newguy.name(), wwn.hashCode())))
                        {
                            newguy.setname(String.format("%s_%05d",newguy.name(), wwn.hashCode()));
                            entities().put(newguy.name(), newguy);
                        }
                        //ports.put(wwn.toLowerCase().replaceAll("[^a-f0-9]",""), zpa.name().replaceAll("\"",""));
                    }
            }
    }


    /**
     * Write an output file, finalizing from entities() if required
     *
     * @param filename name of file to write
     */
    void writeOutputfile(String filename)
    {
        /*
           XmlMapper mapper = new XmlMapper()
           MyBean bean = new MyBean();

           String xml = mapper.writeValueAsString(bean);
           // System.out.println(mapper.writerWithDefaultPrettyPrinter().writeValueAsString(user));

           // we get something like "<MyBean><property>value</property>....</MyBean>"
           MyBean beanFromXml = mapper.readValue(xml, MyBean.class);
         */


        try
        {
            if ( (null != filename) && (filename.equalsIgnoreCase("schema.json")) )
            {
                com.fasterxml.jackson.databind.ObjectMapper mapper = new com.fasterxml.jackson.databind.ObjectMapper();
                JsonSchema schema = mapper.generateJsonSchema(vwimport.getClass());


                //ObjectWriter ow = mapper.writer().withDefaultPrettyPrinter();
                /*
                ObjectWriter ow = mapper.writer(new com.fasterxml.jackson.core.util.DefaultPrettyPrinter());
                	System.out.println(ow.writeValueAsString(schema)); */
                System.out.println(prettyJSON(vwimport));

                //System.out.println(mapper.writer(new com.fasterxml.jackson.core.util.DefaultPrettyPrinter()).writeValueAsString(schema));
            }
            else if ( (null != filename) && (filename.equalsIgnoreCase("orderedtuples.csv")) )
            {
                System.out.println("writing ordered tuples to "+filename);
                try
                {
                    writeOrderedTuples(filename);
                }
                catch (java.io.IOException ioe)
                {
                    System.out.println("IO Exception writing to "+filename+": "+ioe.getMessage());
                }
            }
            else if ( (0 == finalizeEntities()) && (null == vwimport) )
            {
                System.err.println("ERROR: no content loaded (finalized)");
                return;
            }
            else if (
                ( null == filename ) ||
                (filename.equalsIgnoreCase("")) ||
                (filename.equalsIgnoreCase("-"))  )
            {
                System.err.println("NOTE: writing to stdout");
                String o = (new com.fasterxml.jackson.databind.ObjectMapper()).writerWithDefaultPrettyPrinter().writeValueAsString(vwimport);
                System.out.println(o);
            }
            else
            {
                com.fasterxml.jackson.databind.ObjectMapper mapper = new com.fasterxml.jackson.databind.ObjectMapper();
                try
                {
                    mapper.writerWithDefaultPrettyPrinter().writeValue(new File(filename), vwimport);
                }
                catch (java.io.IOException ioe)
                {
                    System.out.println("IO Exception writing to "+filename+": "+ioe.getMessage());
                }
                //JsonParseException,
                //JsonMappingException
            }
        }
        catch (JsonMappingException jme)
        {
            System.err.println("INTERNAL: A JsonMappingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
            System.out.println(jme.getMessage());
        }
        catch (JsonProcessingException jpe)
        {
            System.err.println("INTERNAL: A JsonProcessingException has occurred on output; this needs to be resolved by VI Services.\nPlease communicate the error, and any input text used, as well as the version (0.9-1) to VI Services");
        }
    }

    /**
     * Finalize absorbed Entities: for each entity, transfer from structured tree of Entities to vwimport array for writing
     *
     * @return number of items finalized
     */
    int finalizeEntities()
    {
        Entity e;
        int i = 0;

        for (String s: entities().keySet())
            if ( (null != s) && (null != (e = entities().get(s))) )
                if (e.isOrphan())	/* tree-order transversal: having a parent means this entity will be written when the parent writes */
                    i += e.addTo(vwimport(), "@PACKAGE@-@VERSION@-@BUILDID@");

        //System.out.println("transferred "+i+" entities from "+entities().size()+" entities, resulting in "+vwimport().entities().size()+" json entities");

        return i;
    }


    /**
     * Export an "OrderedTuples.csv" file as a stopgap measure until proper JSON processing can be completed
     *
     * @param name filename to write
     * @throws java.io.IOException when PrintStream throws an exception
     */
    void writeOrderedTuples(String name) throws java.io.IOException
    {
        PrintStream fos = new PrintStream(name);

        Entity e;

        for (String s: entities().keySet())
            if (null != (e = entities.get(s)))
            {
                if (e instanceof EntityHBA)
                {
                    EntityHBA h = (EntityHBA) e;

                    /* name,type,WWPN[,customname] */
                    fos.println(String.format("%s,%s,%s",h.name(),"host",h.wwn()));
                }
                else if (e instanceof EntityFA)
                {
                    EntityFA h = (EntityFA) e;

                    /* name,type,WWPN[,customname] */
                    fos.println(String.format("%s,%s,%s",h.name(),"array",h.wwn()));
                }
            }
    }


    /**
     * Usage messages are useful to those of us with short memories as well (hey, I just need to add swap!)
     *
     * @param progname the name of the program (args[0]) to print on a usage message
     */
    void usage(String progname)
    {
        System.out.println("Usage: "+progname+" -V|--version|-H|--help");
        System.out.println("     : "+progname+" --read <filename>|--input <filename> | -r <filename> | -i <filename>");
        System.out.println("     : "+progname+" --nickname=<filename>|-N<filename> | --removenicknames=<filename> | -i <filename>");

        System.out.println("   ie: "+progname+" --read import.json");
        System.out.println("       "+progname+" -r import.json");
        System.out.println("       "+progname+" -N somenicknames.csv -R existing.csv -oOrderedTuples.csv");
    }


    /**
     * Main function, as you can tell.
     *
     * this function merely parses the command-line to dispatch actions to the meat of the meal above.
     * I'm using an actual GetOpt because, yes, I'm a UNIX/C hack, re-using 3-decades-old knowledge,
     * but this also preserves both extensibility and the ability to use longopts in scripts as a
     * way to self-document what the tool's doing.
     *
     * No real intelligence herein except the parse-and-redirect action.
     *
     * @param args as you'd expect, these are commandline arguments given when the jar is activated
     */
    public static void main(String args[])
    {
        VirtualWisdom4ClientTool m = new VirtualWisdom4ClientTool();

        Vector<LongOpt> options = new Vector(20,2);

        /* Always always ALWAYS provide a quick reference and a version output */
        options.add(new LongOpt("help", LongOpt.NO_ARGUMENT, null, 'H'));
        options.add(new LongOpt("version", LongOpt.NO_ARGUMENT, null, 'V'));

        options.add(new LongOpt("read", LongOpt.REQUIRED_ARGUMENT, null, 'r'));
        options.add(new LongOpt("input", LongOpt.REQUIRED_ARGUMENT, null, 'i'));
        options.add(new LongOpt("nickname", LongOpt.REQUIRED_ARGUMENT, null, 'N'));
        options.add(new LongOpt("remove", LongOpt.REQUIRED_ARGUMENT, null, 'R'));
        options.add(new LongOpt("removenicknames", LongOpt.REQUIRED_ARGUMENT, null, 'R'));
        options.add(new LongOpt("nicknameout", LongOpt.REQUIRED_ARGUMENT, null, 'n'));
        options.add(new LongOpt("output", LongOpt.OPTIONAL_ARGUMENT, null, 'o'));
        options.add(new LongOpt("pattern", LongOpt.REQUIRED_ARGUMENT, null, 'P'));
        options.add(new LongOpt("checkpattern", LongOpt.REQUIRED_ARGUMENT, null, 'p'));

        options.add(new LongOpt("test", LongOpt.REQUIRED_ARGUMENT, null, 'T'));

        /* *@DO_GETOPTJAR_TRUE@/        org.smallfoot.getopt.GetOpt	g = new org.smallfoot.getopt.GetOpt("vw4tool", args, options);        /*@DO_GETOPTJAR_TRUE@ */
        /* *@DO_GETOPTJAR_FALSE@/       gnu.getopt.Getopt		g = new gnu.getopt.Getopt("vw4tool", args, "HVR:r:i:N:n:o::P:p:T:", options.toArray(new LongOpt[0]));        /@DO_GETOPTJAR_FALSE@* */


        int c;
        while ((c = g.getopt()) != -1)
        {
            switch(c)
            {
            case 'i':	/* fall-thru */
            case 'r':   // Read in a config file
            {
                m.load(g.getOptarg());
            }
            break;

            case 'P': /* input chunking-pattern for host-combination and storage-combination */
                m.absorbPattern(g.getOptarg());
                break;

            case 'p': /* exercise chunking-pattern for given alias */
                for (String s: m.exercisePattern(g.getOptarg()))
                    if (null != s)
                        System.out.println("\""+g.getOptarg()+"\" --> \""+s+"\"");
                break;

            case 'N': /* input Nicknames using file://, ftp://, http:// via fibrechannel-parsers fcparsers.jar */
                m.loadAndAbsorbFile(g.getOptarg());
                break;

            case 'R': /* read a list of Nicknames for removal using file://, ftp://, http:// via fibrechannel-parsers fcparsers.jar */
                m.loadAndRemoveFile(g.getOptarg());
                break;



            case 'n': /* output Nicknames as Entities to the given file */
            /* fall-thru */
            case 'o':   // Write a config file out
            {
                m.writeOutputfile(g.getOptarg());
            }
            break;

            /*
             * Testcase generation -- internal use only, used to create bogus internal content to test output format
             */
            case 'T':   // create internal content for export
            {
                if (g.getOptarg().equalsIgnoreCase ("sample01"))
                {
                    VWImport vwimport = new VWImport();
                    VWImport.Entity e = new VWImport.Entity();
                    e.description = "sample01 test entity";
                    e.edit_type = VWImport.Edit_Type.add;
                    e.type = "application";
                    e.name = "sample01_itl";
                    e.itl_patterns = new Vector<VWImport.ITLPattern>();
                    VWImport.ITLPattern i = new VWImport.ITLPattern();
                    i.edit_type = VWImport.Edit_Type.add;
                    i.initiator = "1000002590123456";
                    e.itl_patterns.add(i);
                    vwimport.entities().add(e);
                    System.err.println(vwimport.entities().size() + " entities defined");

                    m.vwimport = vwimport;
                }
                else if (g.getOptarg().equalsIgnoreCase ("sample02"))
                {
                    Entity n = new EntityFA ("sample_02", "10000000c9123456");
                    n.description = "sample02 test FA";
                    m.entities().put(n.name(), n);
                }
                else if (g.getOptarg().equalsIgnoreCase ("sample03"))
                {
                    Entity n = new EntityFA ("NetApp 01 A", "500a098598123456");
                    n.description = "sample03 test NetApp";
                    m.entities().put(n.name(), n);

                    n = new EntityFA ("NetApp 01 B", "500a098698123456");
                    n.description = "sample03 test NetApp";
                    m.entities().put(n.name(), n);

                    n = new EntityHBA ("hba 02 A", "10000000c9123456");
                    n.description = "sample03 test HBA";
                    m.entities().put(n.name(), n);

                    n = new EntityHBA ("hba 02 B", "10000000c9123457");
                    n.description = "sample03 test HBA";
                    m.entities().put(n.name(), n);
                }
                else
                {
                    System.err.println("testcase generation: Testcase \""+g.getOptarg()+"\" is not understood");
                    System.err.println("testcases include: sample01, sample02");
                    return;
                }
            }
            break;

            /*
             * Follows is the "house-keeping": versions, usage, and the catch-all for bad options.
             */
            case 'V':   // print the version and quit
            {
/* *@DO_GETOPTJAR_FALSE@/ System.out.println("@VERSION@-@BUILDID@"); /*@DO_GETOPTJAR_FALSE@ */
/* *@DO_GETOPTJAR_TRUE@/ System.out.println(g.consistentVersion("@VERSION@-@BUILDID@")); /*@DO_GETOPTJAR_TRUE@ */
                return;
            }

            default:
            case '?':
            case 'H':
/* *@DO_GETOPTJAR_FALSE@/ m.usage("vw4tool"); /*@DO_GETOPTJAR_FALSE@ */
/* *@DO_GETOPTJAR_TRUE@/ m.usage(g.progname()); /*@DO_GETOPTJAR_TRUE@ */
                break;
            }
        }
    }
}
